<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"> 
       
<HTML> 
<HEAD> 
  <META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset=UTF-8"> 
  <META NAME="GENERATOR" CONTENT="OpenOffice.org 1.9.118  (Win32)">   
  <TITLE>   Ch 31: Performance</TITLE> 
  <STYLE TYPE="text/css"> 
    TT  {font-size: 12pt; COLOR: BLUE} 
    PRE {font-size: 12pt; COLOR: BLUE} 
                                    
    table.jtable {                  
         border-width: thin;        
         border-spacing: 2px;       
         border-style: solid;       
         border-color: gray;        
         border-collapse: collapse; 
         background-color: white;   
     }                              
     table.jtable td {              
         border-width: 1px;         
         padding: 10px;             
         border-style: solid;       
         border-color: gray;        
         background-color: white;   
     }                              
  </STYLE>
</HEAD>
          
<BODY BGCOLOR=WHITE><!--top jump start--><a href="32.htm">&gt;&gt;</a>&nbsp;
<a href="30.htm">&lt;&lt;</a>&nbsp;
<a href="../user/contents.htm">Usr</a>&nbsp;
<a href="../primer/contents.htm">Pri</a>&nbsp;
<a href="../jforc/contents.htm">JfC</a>&nbsp;
<a href="../learning/contents.htm">LJ</a>&nbsp;
<a href="../phrases/contents.htm">Phr</a>&nbsp;
<a href="../dictionary/contents.htm">Dic</a>&nbsp;
<a href="../dictionary/vocabul.htm">Voc</a>&nbsp;
<a href="../dictionary/xmain.htm">!:</a>&nbsp;
<a href="../index.htm">Help</a>&nbsp;
Learning J<hr><!--top jump end--> 
  <table border="0" cellpadding="5" cellspacing="0"  width="100%"> 
  <tr> <td valign="top" width="17%"> <p> </td> 
   <td valign="top" width="83%"> 
 <A NAME="01"></A>
<H1>Chapter 31: Performance</H1>
This chapter is concerned with performance, that is, the time 
taken to perform a computation, and how to improve it.
<p>
There is one golden rule for achieving good performance in a J program. 
The rule is to try to apply verbs to as much
data as possible at any one time.    
In other words, try to give to a verb 
arguments which are not scalars but vectors or, in general, arrays, 
so as to take maximum advantage 
of the fact that the built-in functions can take array arguments.
<p>
The rest of this chapter consists mostly of harping on this single point.
<p>
<A NAME="02"></A>
<H2>31.1  Measuring the Time Taken</H2>
There is a built-in verb <TT>6!:2</TT> . It takes as argument an expression (as a string)
and returns the time (in seconds) to execute the expression.
For example, given :
<PRE>
<TT>   mat =: ? 256 256 $ 256  NB. a random matrix</TT>
</PRE>
The time in seconds to invert the matrix is given by:
<PRE>
<TT>   6!:2 '%. mat'</TT>
<TT>0.075273</TT>
</PRE>
If we time the same expression again, we see:
<PRE>
<TT>   6!:2 '%. mat'</TT>
<TT>0.0734835</TT>
</PRE>
Evidently there is some uncertainty in this measurement.  
Averaging over several measurements is offered by the 
dyadic case of <TT>6!:2</TT> . 
However, for present purposes we will use monadic <TT>6!:2</TT> to give a rough and ready
but adequate measurement.
<p>
If we intend to compare times for several expressions, it will be convenient 
to introduce a little utility function:
<PRE>
<TT>   compare =: (; (6!:2)) @: > "0       NB. compare timings</TT>
<TT>   </TT>
<TT>   compare '+/ i. 1000' ; '*/ i. 1000'</TT>
<TT>+----------+----------+</TT>
<TT>|+/ i. 1000|2.14228e_5|</TT>
<TT>+----------+----------+</TT>
<TT>|*/ i. 1000|8.44842e_6|</TT>
<TT>+----------+----------+</TT>
<TT>   </TT>
</PRE>
<A NAME="03"></A>
<H2>31.2  The Performance Monitor</H2>
As well as <TT>6!:2</TT>, there is another useful instrument for measuring execution times, called the Performance Monitor.
It shows how much time is spent in each line of, say, an explicit verb.
<p>
Here is an example with a main program and an auxiliary function.
 We are not interested in what it does, only in how it spends its time
 doing it..
<p>
<PRE>
<TT>   main =: 3 : 0</TT>
<TT>    m =. ? 10 10 $ 100x   NB. random matrix</TT>
<TT>    u =. =/ ~ i. 10       NB. unit matrix</TT>
<TT>    t =. aux m            NB. inverted </TT>
<TT>    p =. m +/ . * t</TT>
<TT>    'OK'</TT>
<TT>)</TT>
<TT>    </TT>
<TT>   aux =: 3 : 0</TT>
<TT>    assert. 2 = # $ y        NB. check y is square </TT>
<TT>    assert. =/ $ y  </TT>
<TT>    %. y</TT>
<TT>)  </TT>
</PRE>
We start the monitor: 
<PRE>
<TT>   load 'jpm'</TT>
<TT>   start_jpm_ ''</TT>
<TT>178570</TT>
</PRE>
and then enter the expression to be analyzed
<PRE>
<TT>   main 0                    NB.  expression to be analyzed </TT>
<TT>OK</TT>
</PRE>
To view the reports available: firstly , the main function:
<PRE>
<TT>   showdetail_jpm_ 'main'     NB. display measurements</TT>
<TT> Time (seconds)</TT>
<TT>+--------+--------+---+-----------------+</TT>
<TT>|all     |here    |rep|main             |</TT>
<TT>+--------+--------+---+-----------------+</TT>
<TT>|0.000004|0.000004|1  |monad            |</TT>
<TT>|0.000079|0.000079|1  |[0] m=.?10 10$100|</TT>
<TT>|0.000011|0.000011|1  |[1] u=.=/~i.10   |</TT>
<TT>|0.042640|0.000005|1  |[2] t=.aux m     |</TT>
<TT>|0.062151|0.062151|1  |[3] p=.m+/ .*t   |</TT>
<TT>|0.000015|0.000015|1  |[4] 'OK'         |</TT>
<TT>|0.104900|0.062265|1  |total monad      |</TT>
<TT>+--------+--------+---+-----------------+</TT>
<TT>   </TT>
</PRE>
and we may wish to look at the auxiliary function: 
<PRE>
<TT>   showdetail_jpm_ 'aux'</TT>
<TT> Time (seconds)</TT>
<TT>+--------+--------+---+-----------------+</TT>
<TT>|all     |here    |rep|aux              |</TT>
<TT>+--------+--------+---+-----------------+</TT>
<TT>|0.000004|0.000004|1  |monad            |</TT>
<TT>|0.000004|0.000004|1  |[0] assert. 2=#$y|</TT>
<TT>|0.000010|0.000010|1  |[1] assert. =/$y |</TT>
<TT>|0.042617|0.042617|1  |[2] %.y          |</TT>
<TT>|0.042635|0.042635|1  |total monad      |</TT>
<TT>+--------+--------+---+-----------------+</TT>
</PRE>
Evidently, <TT>main</TT> spends most of its time executing lines <TT>2</TT> and <TT>3</TT> .
 Notice that the time under
 "all"  of line <TT>2</TT> is near enough equal to the time for line <TT>2</TT> "here",
 (that is, in <TT>main</TT> ) plus the time for "total" of <TT>aux</TT>
<A NAME="04"></A>
<H2>31.3   The Golden Rule:  Example 1</H2>
Here is an example of a function which is clearly intended to 
take a scalar argument.
<PRE>
<TT>   collatz =: 3 : 'if. odd y do. 1 + 3 * y else. halve y end.'</TT>
<TT>       odd =: 2 &amp; | </TT>
<TT>       halve  =: -:</TT>
</PRE>
With a vector agument it gives the wrong results 
<PRE>
<TT>   collatz 2 3 4 5 6 7 8 9</TT>
<TT>1 1.5 2 2.5 3 3.5 4 4.5</TT>
</PRE>
So we need to specify the rank to force the argument to be scalar
<PRE>
<TT>   (collatz "0) 2 3 4 5 6 7 8 9</TT>
<TT>1 10 2 16 3 22 4 28</TT>
</PRE>
This is an opportunity for the Golden Rule, so here is a version
designed for a vector argument:
<PRE>
<TT>   veco =: 3 : 0</TT>
<TT>    c =. odd y</TT>
<TT>    (c * 1+3*y) + (1 - c) * (halve y)</TT>
<TT>)</TT>
<TT>   	</TT>
</PRE>
The results are the same:
<PRE>
<TT>   data =: 1 + i. 1e5</TT>
<TT>   </TT>
<TT>   (collatz"0 data) -: (veco data)</TT>
<TT>1</TT>
</PRE>
Here is a variation. 
The adverb <TT> } </TT> is applied to the bit-vector <TT>odd y</TT> to generate a verb, 
and the monadic case of this verb meshes together the first and second items of its argument.
<PRE>
<TT>   meco =: 3 : 0</TT>
<TT>    c =. odd y</TT>
<TT>    (c }) (halve y) ,: (1+3*y) </TT>
<TT>)</TT>
<TT>   </TT>
<TT>   (meco data) -: veco data</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
The  vector versions are faster:
<PRE>
<TT>   compare 'collatz"0 data '  ;  'veco data ' ; 'meco data'</TT>
<TT>+---------------+----------+</TT>
<TT>|collatz"0 data |0.315611  |</TT>
<TT>+---------------+----------+</TT>
<TT>|veco data      |0.0280563 |</TT>
<TT>+---------------+----------+</TT>
<TT>|meco data      |0.00665947|</TT>
<TT>+---------------+----------+</TT>
<TT>   </TT>
<TT>   </TT>
</PRE>
<A NAME="05"></A>
<H2>31.4  Golden Rule Example 2:  Conway's "Life" </H2>
J. H. Conway's celebrated "Game of Life" needs no introduction.
There is a version in J at Rosetta Code, reproduced here:
<PRE>
<TT>   pad=: 0,0,~0,.0,.~]</TT>
<TT>   life=: (_3 _3 (+/ e. 3+0,4&amp;{)@,;._3 ])@pad</TT>
</PRE>
To provide a starting pattern, here is a function <TT>rp</TT> which generates an r-pentomino 
in a y-by-y boolean matrix.
<PRE>
<TT>   rp =: 3 : '4 4 |.  1 (0 1; 0 2; 1 0; 1 1; 2 1) } (y,y) $ 0'</TT>
<TT>   </TT>
<TT>   ] M =: rp 8</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 1 1 0</TT>
<TT>0 0 0 0 1 1 0 0</TT>
<TT>0 0 0 0 0 1 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>   </TT>
<TT>   life  M</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
<TT>0 0 0 0 1 1 1 0</TT>
<TT>0 0 0 0 1 0 0 0</TT>
<TT>0 0 0 0 1 1 0 0</TT>
<TT>0 0 0 0 0 0 0 0</TT>
</PRE>
We notice that the <TT>life</TT> verb contains <TT> ;._3</TT>  - it computes
the count of neighbours of each cell separately, by working on the 3-by-3 neighbourhood of that cell.
<p>
By contrast here is a version which computes all the neighbours-counts
at once, by shifting the whole plane to align each cell with its neighbours.
<PRE>
<TT>   sh   =: |. !. 0</TT>
<TT>   E    =: 0 _1 &amp; sh</TT>
<TT>   W    =: 0 1  &amp; sh</TT>
<TT>   N    =: 1    &amp; sh</TT>
<TT>   S    =: _1   &amp; sh</TT>
<TT>   NS   =: N + S</TT>
<TT>   EW   =: E + W</TT>
<TT>   NeCo =: NS + (+ NS) @: EW                NB. neighbour-count</TT>
<TT>   evol =: ((3 = ]) +. ([ *. 2 = ])) NeCo</TT>
</PRE>
The last line expresses the condition that (neighbour-count is 3)
or ("alive" and count is 2).
The shifting method <TT>evol</TT>, and the Rosetta method <TT>life</TT> give the same result
<PRE>
<TT>   (life M) -: (evol M)</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
However, the shifting method is faster:
<PRE>
<TT>   G =: rp 200   NB. a 200-by-200 grid </TT>
<TT>   </TT>
<TT>   e3 =: 'r3 =: life ^: 100 G NB. 100 iterations, Rosetta'</TT>
<TT>   e4 =: 'r4 =: evol ^: 100 G NB. 100 iterations, shifting'  </TT>
<TT>   compare e3;e4</TT>
<TT>+------------------------------------------------+-------+</TT>
<TT>|r3 =: life ^: 100 G NB. 100 iterations, Rosetta |9.66706|</TT>
<TT>+------------------------------------------------+-------+</TT>
<TT>|r4 =: evol ^: 100 G NB. 100 iterations, shifting|0.24398|</TT>
<TT>+------------------------------------------------+-------+</TT>
<TT>    </TT>
</PRE>
Checking for correctness again: 
<PRE>
<TT>   r3 -: r4  </TT>
<TT>1</TT>
</PRE>
<A NAME="06"></A>
<H2>31.5  Golden Rule Example 3:   Join of Relations</H2>
<H3>31.5.1  Preliminaries</H3>
Recall from <TT><A HREF="18.htm">Chapter 18</A></TT> the author-title and title-subject relations.
We will need test-data in the form of these relations in various sizes. 
It is useful to define a verb to generate test-data from random integers.
(Integers are adequate as substitutes for symbols 
for present purposes.) 
The argument <TT>y</TT> is the number of different titles required.
<PRE>
<TT>   maketestdata =: 3 : 0 </TT>
<TT>    T  =. i. y                                     NB. titles domain</TT>
<TT>    A  =. i. <. 4 * y % 5                          NB. authors domain</TT>
<TT>    S  =. i. <. y % 2                              NB. subjects domain</TT>
<TT>    AT =. (?. (#T) $ # A) ,. (?. (#T) $ #T)        NB. AT relation</TT>
<TT>    TS =. (?. (#T) $  _1+# T) ,. (?. (#T) $ #S)    NB. TS relation</TT>
<TT>    AT;TS</TT>
<TT>)</TT>
<TT>   </TT>
<TT>   </TT>
<TT>   'AT1 TS1' =: maketestdata 12        NB. small   test-data</TT>
<TT>   'AT2 TS2' =: maketestdata 1000      NB. medium</TT>
<TT>   'AT3 TS3' =: maketestdata 10000     NB. large</TT>
</PRE>
<H3>31.5.2  First Method</H3>
Recall also from <TT><A HREF="18.htm">Chapter 18</A></TT> a verb for the join of relations, 
which we will take as a starting-point 
for further comparisons.
We can call this the "first method".
<PRE>
<TT>   VPAIR =: 2 : 0</TT>
<TT>    :</TT>
<TT>    z =.  0 0 $ ''</TT>
<TT>    for_at. x do. z=.z , |: v (#~"1  u) |: at , "1 y end.</TT>
<TT>    ~. z</TT>
<TT>)</TT>
<TT>   </TT>
<TT>   first  =: (1&amp;{ =  2&amp;{) VPAIR (0 3 &amp; {) </TT>
</PRE>
<p>
<TABLE class=jtable>
<TR  VALIGN=TOP>
<TD><TT>AT1</TT></TD>
<TD><TT>TS1</TT></TD>
<TD><TT>AT1 first TS1</TT></TD>
<TR VALIGN=TOP>
<TD><TT>0&nbsp;&nbsp;6<BR>
2&nbsp;&nbsp;8<BR>
1&nbsp;&nbsp;4<BR>
3&nbsp;&nbsp;6<BR>
2&nbsp;&nbsp;5<BR>
1&nbsp;&nbsp;4<BR>
4 10<BR>
1&nbsp;&nbsp;4<BR>
8&nbsp;&nbsp;8<BR>
7&nbsp;&nbsp;7<BR>
3&nbsp;&nbsp;9<BR>
5&nbsp;&nbsp;8</TT></TD>
<TD><TT> 0 0<BR>
 3 2<BR>
 7 4<BR>
 0 0<BR>
 0 5<BR>
 4 4<BR>
 1 4<BR>
10 4<BR>
 8 2<BR>
 4 1<BR>
 1 3<BR>
 5 2</TT></TD>
<TD><TT>2 2<BR>
1 4<BR>
1 1<BR>
4 4<BR>
8 2<BR>
7 4<BR>
5 2</TT></TD>
</TABLE>
<p>
This shows that, for example, if author 5 wrote title 8, 
and title 8 is about subject 2, then author 5 wrote about subject 2.
<H3>31.5.3  Second Method: Boolean Matrix</H3>
Here is another method. It computes a boolean
matrix of equality on the titles.  Row i column j is true
where the title in <TT>i{AT</TT> equals the title in <TT>j{TS</TT> . 
The authors and titles are recovered by converting the boolean matrix to sparse representation, 
then taking its index-matrix.
<PRE>
<TT>   second =: 4 : 0</TT>
<TT>    'a t'  =. |: x</TT>
<TT>    'tt s' =. |:  y</TT>
<TT>    bm     =. t =/ tt            NB. boolean matrix of matches   </TT>
<TT>    sm     =. $. bm              NB. convert to sparse </TT>
<TT>    im     =: 4 $. sm            NB. index-matrix</TT>
<TT>    'i j'  =. |: im             </TT>
<TT>    (i { a),. (j { s)</TT>
<TT>)</TT>
</PRE>
Now to check the second method for correctness, that is, 
giving the same results
as the first.  We don't care about ordering, and we don't care about 
repetitions, so
let us say that two relations are the same
iff their sorted nubs match.
<PRE>
<TT>   same =: 4 : '(~. x /: x) -: (~. y /: y)	'</TT>
<TT>   </TT>
<TT>   (AT2 second TS2)  same (AT2 first TS2)</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
Now for some times
<PRE>
<TT>   t1 =: 6!:2 'AT2 first TS2'</TT>
<TT>   t2 =: 6!:2 'AT2 second AT2'</TT>
<TT>   t3 =: 6!:2 'AT3 first TS3'</TT>
<TT>   t4 =: 6!:2 'AT3 second TS3'</TT>
<TT>   </TT>
<TT>   3 3 $ ' '; (#AT2) ; (#AT3) ; 'first' ; t1; t3 ; 'second' ; t2; t4</TT>
<TT>+------+----------+--------+</TT>
<TT>|      |1000      |10000   |</TT>
<TT>+------+----------+--------+</TT>
<TT>|first |0.0356744 |7.916   |</TT>
<TT>+------+----------+--------+</TT>
<TT>|second|0.00337303|0.321806|</TT>
<TT>+------+----------+--------+</TT>
<TT>   </TT>
</PRE>
We see that the advantage of the second method is reduced at the larger size,
and we can guess this is because
the time to compute the boolean matrix is quadratic in the size.
We can use the performance monitor to see where the time goes.
<PRE>
<TT>   require 'jpm'</TT>
<TT>   start_jpm_ ''</TT>
<TT>178570</TT>
<TT>   z =: AT3 second TS3</TT>
<TT>   showdetail_jpm_ 'second'     NB. display measurements</TT>
<TT> Time (seconds)</TT>
<TT>+--------+--------+---+----------------+</TT>
<TT>|all     |here    |rep|second          |</TT>
<TT>+--------+--------+---+----------------+</TT>
<TT>|0.000007|0.000007|1  |dyad            |</TT>
<TT>|0.000329|0.000329|1  |[0] 'a t'=.|:x  |</TT>
<TT>|0.000208|0.000208|1  |[1] 'tt s'=.|:y |</TT>
<TT>|0.177003|0.177003|1  |[2] bm=.t=/tt   |</TT>
<TT>|0.131638|0.131638|1  |[3] sm=.$.bm    |</TT>
<TT>|0.000009|0.000009|1  |[4] im=:4$.sm   |</TT>
<TT>|0.000160|0.000160|1  |[5] 'i j'=.|:im |</TT>
<TT>|0.017383|0.017383|1  |[6] (i{a),.(j{s)|</TT>
<TT>|0.326736|0.326736|1  |total dyad      |</TT>
<TT>+--------+--------+---+----------------+</TT>
<TT>   </TT>
</PRE>
Evidently much of the time went into computing the boolean matrix at line <TT>2</TT>.
Can we do better than this?
<H3>31.5.4  Third method: boolean matrix with recursive splitting</H3>
Here is an attempt to avoid the quadratic time.  
If the argument is smaller than a certain size,
we use the second method above (which is quadratic, but 
not so bad for smaller arguments). 
<p>
If the argument is larger than a certain size, we split it into 
two smaller parts, so that there are no titles shared between the two. 
Then the method is applied recursively to the parts.
<p>
By experimenting, the "certain size" appears to be about 256
on my computer.
<PRE>
<TT>   third =: 4 : 0</TT>
<TT>    if. 0 = # x do. return.  0 2 $ 3 end.</TT>
<TT>    if. 0 = # y do. return.  0 2 $ 3 end.</TT>
<TT>    'a t'  =. |: x</TT>
<TT>    'tt s' =. |: y</TT>
<TT>    if. 256 > # x do.</TT>
<TT>        bm     =. t =/ tt             NB. boolean matrix of matches   </TT>
<TT>        sm     =. $. bm</TT>
<TT>        im     =. 4 $. sm             NB. index-matrix</TT>
<TT>        'i j'  =. |: im             </TT>
<TT>       (i { a),. (j { s)</TT>
<TT>    else.</TT>
<TT>        p  =:  <. -: (>./t) + (<./t)  NB. choose "pivot" title  </TT>
<TT>        pv =: t <: p</TT>
<TT>        x1 =. pv # x</TT>
<TT>        x2 =. (-. pv) # x</TT>
<TT>        assert. (#x1) < (#x)</TT>
<TT>        assert.  (#x2) < (#x)</TT>
<TT>        qv =. tt <: p</TT>
<TT>        y1 =. qv # y</TT>
<TT>        y2 =. (-. qv) # y</TT>
<TT>        assert. (#y1) < (#y)</TT>
<TT>        assert. (#y2) < (#y)</TT>
<TT>        (x1 third y1) , (x2 third y2)</TT>
<TT>    end.</TT>
<TT>)</TT>
<TT>           	</TT>
</PRE>
Check correctness :
<PRE>
<TT>   (AT2 third TS2) same (AT2 second TS2)</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
And timings. Experiment on my computer shows the second method 
will run out of space where the third method will succeed.
<PRE>
<TT>   'AT4 TS4' =: maketestdata  30000</TT>
<TT>   'AT5 TS5' =: maketestdata 100000</TT>
<TT>   t4a =: 6!:2 'AT4 second TS4'</TT>
<TT>   t5  =: 6!:2 'AT2 third TS2'</TT>
<TT>   t6  =: 6!:2 'AT3 third TS3'</TT>
<TT>   t7  =: 6!:2 'AT4 third TS4'</TT>
<TT>   t8  =: 6!:2 'AT5 third TS5'</TT>
<TT>   a =:  ' ';     (#AT2); (#AT3) ; (#AT4); (#AT5)</TT>
<TT>   b =:  'second'; t2;    t4;       t4a;  'limit error'</TT>
<TT>   c =:  'third' ; t5;    t6;       t7  ;  t8</TT>
<TT>   </TT>
<TT>   3 5 $a,b,c</TT>
<TT>+------+----------+---------+---------+-----------+</TT>
<TT>|      |1000      |10000    |30000    |100000     |</TT>
<TT>+------+----------+---------+---------+-----------+</TT>
<TT>|second|0.00337303|0.321806 |3.05887  |limit error|</TT>
<TT>+------+----------+---------+---------+-----------+</TT>
<TT>|third |0.00134601|0.0173196|0.0553821|0.192562   |</TT>
<TT>+------+----------+---------+---------+-----------+</TT>
<TT>   </TT>
</PRE>
In conclusion, the third method is clearly superior but
considerably more complex.
<A NAME="07"></A>
<H2>31.6  Golden Rule Example 4: Mandelbrot Set</H2>
The Mandelbrot Set is a fractal image needing much computation to
produce. In writing the following, I have found to be helpful 
this  
<A href="http://en.wikipedia.org/wiki/Mandelbrot_set">Wikipedia article </A> .
<p>
<p>
Computation of the image requires, for every pixel in the image, iteration of a single scalar function until a condition is satisfied. 
Different pixels will require different numbers of iterations.  The final result is the array of counts of iterations for each pixel.  
Hence it may appear 
that the Mandelbrot Set is an inescapably scalar computation.  It is not, as the following is meant to show. The Golden Rule applies.
<p>
<H3>31.6.1  Scalar Version</H3>
The construction of an image begins with choosing a grid of points on the complex plane,
one for each pixel in the image. Here is a verb  for conveniently constructing the grid.    
<PRE>
<TT>   makegrid =: 4 : 0</TT>
<TT>'m n' =. x </TT>
<TT>'px py qx qy ' =. , +. y</TT>
<TT>(|. py + (i.m) * ((qy-py) % m-1)) (j.~ /) (px + (i.n) * ((qx-px) % n-1)) </TT>
<TT>)</TT>
<TT>   </TT>
</PRE>
The left argument specifies the grid as m-by-n pixels.
The right argument specifies the positions of lower-left and upper-right corners 
of the image as points in the complex plane. 
<p>
To demonstrate with a tiny grid:
<PRE>
<TT>   3 4 makegrid 0j0 3j4</TT>
<TT>0j4 1j4 2j4 3j4</TT>
<TT>0j2 1j2 2j2 3j2</TT>
<TT>  0   1   2   3</TT>
<TT>   </TT>
</PRE>
For a Mandelbrot image, this is more suitable: 
<PRE>
<TT>   GRID =:  400 700 makegrid _2.5j_1 1j1</TT>
<TT>    </TT>
</PRE>
Here, the right argument is chosen to be <TT>_2.5j_1 1j1</TT>
 because it is known that the 
whole of the Mandelbrot image is contained within this region of the complex plane.
Notice that this region is a rectangle with sides in the ration 4 : 7. 
The left argument, m-by-n pixels, is chosen to be 
in the same ratio. 
<p>
The image is computed by applying a Mandelbrot function to each pixel in the grid.
Here is a suitable Mandelbrot function. It follows the design outlined in the Wikipedia article, 
<PRE>
<TT>   mfn1 =: 3 : 0  </TT>
<TT>    NB.        y is one pixel-position</TT>
<TT>    v =. 0j0</TT>
<TT>    n =. 0</TT>
<TT>    while. (2 > | v) *. (n < MAXITER) do.</TT>
<TT>        v  =. y + *: v</TT>
<TT>        n =. n+1</TT>
<TT>    end.</TT>
<TT>    n</TT>
<TT>)</TT>
<TT>   </TT>
</PRE>
We need to choose a value for <TT>MAXITER</TT>, the maximum number of iterations. 
The higher the maximum, the more complex the resulting image.
For present purposes let us choose a maximum of 64 iterations, 
which will give a recognisable image.
<PRE>
<TT>   MAXITER =: 64                NB. maximum number of iterations</TT>
<TT>   </TT>
<TT>   image1 =: mfn1 " 0  GRID</TT>
</PRE>
The result <TT>image1</TT> is a matrix of integers, which can be mapped to colors and then
displayed on-screen with:
<PRE>
<TT>require '~addons/graphics/viewmat/viewmat.ijs' </TT>
<TT></TT>
</PRE>
<PRE>
<TT>viewmat image1</TT>
<TT></TT>
</PRE>
to produce an image looking something like this:
<p>
<IMG SRC="31image1.bmp" WIDTH=350 HEIGHT=200><p> 
<H3>31.6.2  Planar Version</H3>
Now we look at a version which computes all pixels at once.  
Here is a first attempt.  It is is a straightforward development of <TT>mfn1</TT>
but here all the computations for every pixel are allowed to 
run for the maximumum number of iterations. 
<PRE>
<TT>   mfn3  =: 3 : 0           NB. y is entire grid</TT>
<TT>    N =. ($ y) $ 0</TT>
<TT>    v =. 0j0</TT>
<TT>    for_k. i. MAXITER-1 do.</TT>
<TT>        v =. y + *: v</TT>
<TT>        N =. N + (2 > | v) </TT>
<TT>    end.</TT>
<TT>    1 + N</TT>
<TT>)</TT>
</PRE>
For small values of <TT>MAXITER</TT>, this is OK. 
A quick demonstration, firstly of correctness: 
it produces the same result as <TT>mfn1</TT>.
<PRE>
<TT>   MAXITER =: 9</TT>
<TT>   </TT>
<TT>   (mfn1 " 0 GRID) -: (mfn3 " 2 GRID)</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
And it's faster:
<PRE>
<TT>   e3a =: 'mfn1 " 0 GRID  NB. Wikip. with MAXITER=9' </TT>
<TT>   e3b =: 'mfn3 " 2 GRID  NB. Planar with MAXITER=9' </TT>
<TT>   compare e3a;e3b</TT>
<TT>+----------------------------------------+--------+</TT>
<TT>|mfn1 " 0 GRID  NB. Wikip. with MAXITER=9|6.06934 |</TT>
<TT>+----------------------------------------+--------+</TT>
<TT>|mfn3 " 2 GRID  NB. Planar with MAXITER=9|0.168251|</TT>
<TT>+----------------------------------------+--------+</TT>
<TT>   </TT>
</PRE>
Unfortunately there is a problem with any larger values of <TT>MAXITER</TT>.
The repeated squaring of the complex numbers in <TT>v</TT>  will ultimately produce, 
not infinity, but a "NaN Error", caused by subtracting infinities.
Observe:
<PRE>
<TT>   (*: ^: 9) 1j3  NB. this is OK</TT>
<TT>1.96052e255j_9.80593e255</TT>
<TT>   </TT>
<TT>   (*: ^: 30) 1j3  NB. but this is not</TT>
<TT>|NaN error</TT>
<TT>|       (*:^:30)1j3</TT>
<TT>|[-589] c:\users\homer\X15\temp.ijs</TT>
<TT>   </TT>
</PRE>
Here is an attempt to avoid the NaN errors. One cycle in every 8,
those values in <TT>v</TT> which have "escaped", (that is,  no longer contribute to
the final result <TT>N</TT>)  are reset to small values to prevent them increasing without limit.
<PRE>
<TT>   mfn4 =: 3 : 0</TT>
<TT>    N =. ($ y) $ 0</TT>
<TT>    v =. 0j0</TT>
<TT>    for_k.  i. MAXITER - 1  do.  </TT>
<TT>        v =. y + *: v</TT>
<TT>        N =. N + 2 > | v</TT>
<TT>        if. 0 = 8 | k do. </TT>
<TT>            e =. N < k	             </TT>
<TT>            v =. e } v ,: 1.5j1.5 </TT>
<TT>        end.	</TT>
<TT>    end.</TT>
<TT>    N+1</TT>
<TT>)</TT>
<TT>   </TT>
</PRE>
In spite of the burden of resetting, 
the timing looks about 10 times faster than the scalar method:
<PRE>
<TT>   MAXITER =: 64</TT>
<TT>   e1 =: 'image1 =: mfn1 " 0 GRID NB. Scalar'</TT>
<TT>   e4 =: 'image4 =: mfn4 " 2 GRID NB. Planar, resetting'</TT>
<TT>   compare e1 ; e4</TT>
<TT>+---------------------------------------------+-------+</TT>
<TT>|image1 =: mfn1 " 0 GRID NB. Scalar           |17.6847|</TT>
<TT>+---------------------------------------------+-------+</TT>
<TT>|image4 =: mfn4 " 2 GRID NB. Planar, resetting|1.50849|</TT>
<TT>+---------------------------------------------+-------+</TT>
<TT>   </TT>
</PRE>
and we check the result is correct:
<PRE>
<TT>   image4 -: image1</TT>
<TT>1</TT>
<TT>   </TT>
</PRE>
<H2>31.7   The Special Code of Appendix B of the Dictionary</H2>
In <A href="http://www.jsoftware.com/help/dictionary/special.htm">
Appendix B of the J Dictionary </A> there are listed about 80
different expressions which are given special treatment by the
interpreter to improve performance.  Many more expressions are listed in the
<A href="http://www.jsoftware.com/help/release/contents.htm"> Release Notes</A>
<p>
An example is <TT>+/</TT> . Notice that the 
speedup only occurs when <TT>+/</TT> itself (as opposed to something equivalent) is recognised. 
<PRE>
<TT>   data =: ? 1e6 $ 1e6  NB. a million random integers</TT>
<TT>   </TT>
<TT>   plus =: +</TT>
<TT>   </TT>
<TT>   </TT>
<TT>   compare 'plus / data' ; '+/ data'</TT>
<TT>+-----------+----------+</TT>
<TT>|plus / data|0.220362  |</TT>
<TT>+-----------+----------+</TT>
<TT>|+/ data    |0.00157533|</TT>
<TT>+-----------+----------+</TT>
<TT>   </TT>
<TT>   </TT>
</PRE>
The special expressions can be unmasked with the <TT>f.</TT>
adverb which translates all defined names into the built-in
functions.
<PRE>
<TT>   foo =: plus /</TT>
<TT>   </TT>
<TT>   compare 'foo data'; 'foo f. data' </TT>
<TT>+-----------+----------+</TT>
<TT>|foo data   |0.221123  |</TT>
<TT>+-----------+----------+</TT>
<TT>|foo f. data|0.00160007|</TT>
<TT>+-----------+----------+</TT>
<TT>   </TT>
</PRE>
The recommendation here is NOT that the programmer should look for opportunities to use these special cases. The recommendation is
ONLY to allow the interpreter to find them, by giving, where appropriate, a final little polish to tacit definitions with <TT>f.</TT> .
<p>
This brings us to the end of Chapter 31
  </tr> </table> 
<HR>  
 <p ALIGN=CENTER> 
 <A HREF="32.htm"> NEXT </A> <BR> 
 <A HREF="contents.htm#toc"> Table of Contents </A> <BR> 
<A HREF="kwic.htm"> Index </A> 
<HR> 
<P ALIGN=CENTER> 
<FONT SIZE=-1>The examples in this chapter 
were executed using J version 802 beta. 
 This chapter last updated 21 Jun 2015<BR> 
Copyright &copy; Roger Stokes 2014. 
 This material may be freely reproduced, 
provided that acknowledgement is made. 
</FONT> 
 <!--bottom jump start--><hr><a href="32.htm">&gt;&gt;</a>&nbsp;
<a href="30.htm">&lt;&lt;</a>&nbsp;
<a href="../user/contents.htm">Usr</a>&nbsp;
<a href="../primer/contents.htm">Pri</a>&nbsp;
<a href="../jforc/contents.htm">JfC</a>&nbsp;
<a href="../learning/contents.htm">LJ</a>&nbsp;
<a href="../phrases/contents.htm">Phr</a>&nbsp;
<a href="../dictionary/contents.htm">Dic</a>&nbsp;
<a href="../dictionary/vocabul.htm">Voc</a>&nbsp;
<a href="../dictionary/xmain.htm">!:</a>&nbsp;
<a href="../index.htm">Help</a>&nbsp;
Learning J<!--bottom jump end--></BODY> 
 </HTML> 
 
